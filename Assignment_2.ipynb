{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/makennajohnstone/Lab6/blob/master/Assignment_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jrGUQYTLzJiE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "## Printed copy due in class on October 15, 2018\n",
        "\n",
        "You may work in pairs on this assignment. You are not permitted to discuss this assignment with anyone other than your partner or the instructors.\n",
        "\n",
        "## Student 1: Likhita Narayana\n",
        "## Student 2: Anna Rulloda"
      ]
    },
    {
      "metadata": {
        "id": "6ohmF3mszJiG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question 1: Maximum Likelihood\n",
        "\n",
        "The Weibull distribution is widely used to model failure times. Its p.d.f. is \n",
        "\n",
        "$$ p(x) = \\frac{\\beta}{\\alpha} \\left( \\frac{x}{\\alpha} \\right)^{\\beta - 1} e^{-\\left(\\frac{x}{\\alpha}\\right)^\\beta}. $$\n",
        "\n",
        "The data in `/data400/test_coupons_failure.csv` contain the cycles to failure of aluminum test coupons subjected to repeated alternating stress of 15,000 psi at 20 cycles per second. In this question, you will use the Weibull distribution to model this data.\n",
        "\n",
        "For some parts, you will be able to calculate the maximum likelihood analytically (i.e., by taking the derivative and setting it equal to 0). You should show your work in this case. (I encourage you to typeset math equations using LaTeX. The p.d.f. above was typeset using LaTeX, for example.) For others, you will calculate the maximum likelihood numerically. You should show your code in this case."
      ]
    },
    {
      "metadata": {
        "id": "ysqyWkErzJiI",
        "colab_type": "code",
        "outputId": "edfb7ce1-2ebc-45b9-ce6a-1dd9917b547e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#cycles = pd.read_csv(\"/data400/test_coupons_failure.csv\")[\"cycles\"]\n",
        "cycles = [8078,1891,13912,3407,6168,15504,1893,12551,6861,1334,9438,6227,2562,2074,6770,7971,17081,9245,19041,21997]\n",
        "sumCycles = sum(cycles)\n",
        "avgCycles = sumCycles/len(cycles)\n",
        "print(avgCycles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8700.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T0TI3tKDzJiL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part A. Unknown $\\alpha$\n",
        "\n",
        "Suppose you want to model the distribution by a Weibull where $\\beta=2.0$. Find the maximum likelihood estimate (MLE) of $\\alpha$."
      ]
    },
    {
      "metadata": {
        "id": "k-e73qW-zJiM",
        "colab_type": "code",
        "outputId": "b19a02b6-a719-4306-9e34-5369e5769ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def likelihood_alpha(a, x):\n",
        "    return (2/a)*(x*1.0/a)**(2-1) * np.exp((x*1.0/a) ** 2)\n",
        "\n",
        "# Define the negative likelihood\n",
        "def neg_likelihood_alpha(a, x):\n",
        "    return -(2/a)*(x*1.0/a)**(2-1) * np.exp((x*1.0/a) ** 2) \n",
        "\n",
        "def neg_log_likelihood_alpha(a, x=8700.25):\n",
        "    #print(\"a = {} and x = {}\".format(a, x))\n",
        "    return -1 * (np.log(2) - np.log(a) + (2 - 1)*(np.log(x) - np.log(a)) - ((x/a)**2))\n",
        "  \n",
        "\n",
        "minimize(neg_log_likelihood_alpha, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fun: 9.378057289080559\n",
              " hess_inv: array([[13768812.59312459]])\n",
              "      jac: array([-3.09944153e-06])\n",
              "  message: 'Optimization terminated successfully.'\n",
              "     nfev: 144\n",
              "      nit: 47\n",
              "     njev: 48\n",
              "   status: 0\n",
              "  success: True\n",
              "        x: array([8639.87708318])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "X2bmZfQ4zJiP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part B. Unknown $\\beta$\n",
        "\n",
        "Suppose you want to model the distribution by a Weibull where $\\alpha=8000$. Find the MLE of $\\beta$."
      ]
    },
    {
      "metadata": {
        "id": "r-S125oQzJiP",
        "colab_type": "code",
        "outputId": "4007758f-0f62-49d8-c2f5-e3ec43a311b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "def neg_log_likelihood_beta(b):\n",
        "    return -1 * (np.log(b) - np.log(8000) + (b - 1)*(np.log(8700.25) - np.log(8000)) - ((8700.25/8000)**b))\n",
        "      \n",
        "      \n",
        "minimize(neg_log_likelihood_beta, .1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fun: 8.241704609433187\n",
              " hess_inv: array([[37.45622023]])\n",
              "      jac: array([-5.96046448e-07])\n",
              "  message: 'Optimization terminated successfully.'\n",
              "     nfev: 33\n",
              "      nit: 9\n",
              "     njev: 11\n",
              "   status: 0\n",
              "  success: True\n",
              "        x: array([9.61103269])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "nkFcO7bWzJiS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part C. Unknown $\\alpha$ and $\\beta$\n",
        "\n",
        "Suppose you are unsure what either $\\alpha$ or $\\beta$ should be, so you would like to learn both parameters from data. Find the MLE of $(\\alpha, \\beta)$."
      ]
    },
    {
      "metadata": {
        "id": "0DkHOTKizJiT",
        "colab_type": "code",
        "outputId": "819aa678-a554-476b-cbe6-3e403510a359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "def neg_log_likelihood_alpha_beta(ab):\n",
        "    a,b = ab\n",
        "    #print(\"a = {}, b = {}\".format(a, b))\n",
        "    return -1 * (np.log(b) - np.log(a) + (b - 1)*(np.log(8700.25) - np.log(a)) - ((8700.25/a)**b))\n",
        "  \n",
        "  \n",
        "#Define the negative likelihood\n",
        "def neg_likelihood_alpha_beta(ab):\n",
        "  a,b = ab\n",
        "  #print(\"a = {}, b = {}\".format(a,b))\n",
        "  return -(b*1.0/a)*(8700.25/a)**(b-1) * np.exp((8700.25/a) ** b) \n",
        "      \n",
        "\n",
        "init_guess = [1,1]\n",
        "print(\"Unknown alpha and beta using negative log likelihood function\")\n",
        "minimize(neg_log_likelihood_alpha_beta, init_guess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unknown alpha and beta using negative log likelihood function\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in double_scalars\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fun: nan\n",
              " hess_inv: array([[1, 0],\n",
              "       [0, 1]])\n",
              "      jac: array([nan, nan])\n",
              "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
              "     nfev: 448\n",
              "      nit: 1\n",
              "     njev: 112\n",
              "   status: 2\n",
              "  success: False\n",
              "        x: array([  114.32960707, -1027.01205137])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "yywoeDjNSp7l",
        "colab_type": "code",
        "outputId": "5153a441-519d-4c68-a92a-5419d9661d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "init_guess_2 = [.1,.1]\n",
        "print(\"Unknown alpha and beta using negative likelihood function\")\n",
        "minimize(neg_likelihood_alpha_beta, init_guess_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unknown alpha and beta using negative likelihood function\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py:628: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py:628: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fun: nan\n",
              " hess_inv: array([[1, 0],\n",
              "       [0, 1]])\n",
              "      jac: array([nan, nan])\n",
              "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
              "     nfev: 172\n",
              "      nit: 1\n",
              "     njev: 43\n",
              "   status: 2\n",
              "  success: False\n",
              "        x: array([-3.31850749, 47.28134193])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "ZGiQLcagzJiV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part D. Plot your results\n",
        "\n",
        "Make a histogram of the coupon cycles data. You learned three different Weibull distributions in Parts A-C above. Show the p.d.f.s of these three distributions on top of the histograms. Which p.d.f. seems to fit the data the best?"
      ]
    },
    {
      "metadata": {
        "id": "esSn6yfFzJiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weibull(a, b, x):\n",
        "    return (b*1.0/a)*(x*1.0/a)**(b-1) * np.exp((x*1.0/a)**b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mco-wcfnLIKQ",
        "colab_type": "code",
        "outputId": "5ab8a6bb-ec84-4272-9453-04209af24a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "unknown_alpha_histogram_cycles = []\n",
        "unknown_beta_histogram_cycles = []\n",
        "unknown_alpha_beta_histogram_cycles = []\n",
        "\n",
        "for i in cycles:\n",
        "  #print(\"i = {}\".format(i))\n",
        "  unknown_alpha_histogram_cycles.append(weibull(8639.87708318, 2.0, i))\n",
        "  unknown_beta_histogram_cycles.append(weibull(8000, 9.61103269, i))\n",
        "  unknown_alpha_beta_histogram_cycles.append(weibull(47.28134193,3.31850749, i))\n",
        "\n",
        "print(\"unknown_alpha_histogram_cycles = {}\".format(unknown_alpha_histogram_cycles))\n",
        "print(\"unknown_beta_histogram_cycles = {}\".format(unknown_beta_histogram_cycles))\n",
        "print(\"unknown_alpha_beta_histogram_cycles = {}\".format(unknown_alpha_beta_histogram_cycles))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unknown_alpha_histogram_cycles = [0.000518755858333301, 5.3150903952468276e-05, 0.004982303564395124, 0.00010663986785663247, 0.0002751048313744785, 0.010397766347830238, 5.321251313350473e-05, 0.002774464759475535, 0.0003453599794282105, 3.6603620673643214e-05, 0.000833935940752901, 0.0002804706404880341, 7.495179514043316e-05, 5.8863942457460044e-05, 0.0003351633827953264, 0.000500243159978609, 0.022802023291798024, 0.0007783612339424326, 0.06562281037868654, 0.38502861965617263]\n",
            "unknown_beta_histogram_cycles = [0.0039147882461654845, 4.850012766561699e-09, 5.2962249889294535e+87, 7.718542665302634e-07, 0.0001389210650950359, 3.041367312697741e+250, 4.89436194598249e-09, 4.940678488146441e+31, 0.0004022962282790148, 2.403607894622127e-10, 0.6680828882542612, 0.00015198046565726185, 6.628855419455278e-08, 1.0744697541561236e-08, 0.00034886733538653424, 0.0030584162856783707, inf, 0.23146845539184685, inf, inf]\n",
            "unknown_alpha_beta_histogram_cycles = [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "izDJKI0cOTS7",
        "colab_type": "code",
        "outputId": "f948b371-3724-4889-8dcc-79ed1216b320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(unknown_alpha_histogram_cycles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([18.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
              " array([3.66036207e-05, 3.85358052e-02, 7.70350068e-02, 1.15534208e-01,\n",
              "        1.54033410e-01, 1.92532612e-01, 2.31031813e-01, 2.69531015e-01,\n",
              "        3.08030216e-01, 3.46529418e-01, 3.85028620e-01]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEbdJREFUeJzt3XuwXWV9xvFvmiO1wYMe7NYA4zSD\nOr8W4x8V7ZChmiheGR3GElta6lTEXgAZppaxsc5oo63S2jQj0KllKqXSQQFREmtELFpQ0dGm6uCl\nv1IqHUxkOJVTCcZCbv3jrEy3m3PZWfv2hvf7mWGy91rvu9fDm+TZK2tfzopDhw4hSarHT006gCRp\nvCx+SaqMxS9JlbH4JakyFr8kVWZq0gEOm53d0/rtRTMzq5ib2zvMOENVcr6Ss0HZ+UrOBmXnKzkb\nlJ2vN1unM73iSB/jcXHGPzW1ctIRllRyvpKzQdn5Ss4GZecrORuUnW8Y2R4XxS9J6p/FL0mVsfgl\nqTIWvyRVxuKXpMpY/JJUGYtfkipj8UtSZSx+SapMMV/ZMIjX/MG2iRz36k0vmchxJWkQnvFLUmX6\nOuOPiLXANmBrZl4ZETcCnWb38cCXM/N3usa/AXg3cE+z6TOZ+adDSy1Jam3Z4o+IY4ErgNsOb8vM\n13Xtvxr42wWmXp+Zlw4jpCRpePq51PMIcCawu3dHRATwlMz8yrCDSZJGY9kz/szcD+yf7/jHuIT5\nfw0sZH1E3AI8Abg0M7+21HFmZlYV/VWoC+l0pkcydtxKzgZl5ys5G5Sdr+RsUHa+QbO1fldPRBwD\n/HJmXrjA7i8Ds5n5yYhYB3wIeO5Sj1fqDz1Yyuzsnr7GdTrTfY8dt5KzQdn5Ss4GZecrORuUna83\nW5sngUHe1bMeWPAST2b+W2Z+srn9JaATEUfX6bwkPU4NUvwvAL6x0I6IeGtE/Hpzey3zZ/8HBjiW\nJGlI+nlXz6nAFmANsC8iNgK/ApzA/79d8/DYbZl5FnAdcG1E/F5zjPOHnFuS1FI/L+7uBDYssOvi\nBcae1fz6PeDFg4aTJA2fn9yVpMpY/JJUGYtfkipj8UtSZSx+SaqMxS9JlbH4JakyFr8kVcbil6TK\nWPySVBmLX5IqY/FLUmUsfkmqjMUvSZWx+CWpMha/JFXG4pekylj8klQZi1+SKmPxS1Jllv1h6wAR\nsRbYBmzNzCsj4hrgVOAHzZD3ZeYne+ZsBU4DDgGXZOZXh5ZaktTassUfEccCVwC39ex6W2b+4yJz\n1gPPzsx1EfELwNXAukHDSpIG18+lnkeAM4HdR/C4ZwA3A2Tmd4CZiDjuyONJkoZt2TP+zNwP7I+I\n3l1vjoi3AA8Ab87M/+7atxrY2XV/ttn20GLHmZlZxdTUyn5zF6HTmR7J2HErORuUna/kbFB2vpKz\nQdn5Bs3W1zX+BVwL/CAzvx4Rm4A/Bt68xPgVyz3g3NzellEmZ3Z2T1/jOp3pvseOW8nZoOx8JWeD\nsvOVnA3Kztebrc2TQKviz8zu6/3bgb/uGbKb+TP8w04Evt/mWJKk4Wr1ds6IuCkiTm7ubgC+2TPk\nVmBjM/Z5wO7MLPPpU5Iq08+7ek4FtgBrgH0RsZH5d/lcHxF7gYeB85qxHwHOy8w7I2JnRNwJHAQu\nGlF+SdIR6ufF3Z3Mn9X3ummBsed03d40UDJJ0kj4yV1JqozFL0mVsfglqTIWvyRVxuKXpMpY/JJU\nGYtfkipj8UtSZSx+SaqMxS9JlbH4JakyFr8kVcbil6TKWPySVBmLX5IqY/FLUmUsfkmqjMUvSZWx\n+CWpMha/JFVm2R+2DhARa4FtwNbMvDIingH8HfAEYB/wm5l5f9f4DcCNwLeaTXdl5sXDDC5JamfZ\n4o+IY4ErgNu6Nv8JcFVm3hARFwFvAd7aM/X2zNw4tKSSpKHo51LPI8CZwO6ubRcCNzW3Z4GnDjmX\nJGlElj3jz8z9wP6I6N72I4CIWAlcBLxrgamnRMR24Hhgc2Z+ZqnjzMysYmpq5RFEn7xOZ3okY8et\n5GxQdr6Ss0HZ+UrOBmXnGzRbX9f4F9KU/rXAZzPztp7ddwObgRuAk4HPRcSzMvPRxR5vbm5v2ygT\nMzu7p69xnc5032PHreRsUHa+krNB2flKzgZl5+vN1uZJoHXxM//i7t2Zubl3R2buAq5v7t4TEfcD\nJwHfHeB4kqQhaPV2zog4F3g0M9+52P6IuLS5vRp4OrCrdUpJ0tD0866eU4EtwBpgX0RsBJ4G/G9E\n/HMz7NuZeWFEfAQ4D9gOXBcRZwHHABcsdZlHkjQ+/by4uxPY0M+DZeY5XXdf0zKTJGmE/OSuJFXG\n4pekylj8klQZi1+SKmPxS1JlLH5JqozFL0mVsfglqTIWvyRVxuKXpMpY/JJUGYtfkipj8UtSZSx+\nSaqMxS9JlbH4JakyFr8kVcbil6TKWPySVBmLX5Iqs+wPWweIiLXANmBrZl4ZEc8ArgVWAt8HXp+Z\nj/TM2QqcBhwCLsnMrw41uSSplWXP+CPiWOAK4Lauze8C/iozXwj8B/DGnjnrgWdn5jrgfODyoSWW\nJA2kn0s9jwBnAru7tm0Atje3PwG8tGfOGcDNAJn5HWAmIo4bKKkkaSiWvdSTmfuB/RHRvfnYrks7\nDwAn9ExbDezsuj/bbHtosePMzKxiamplP5mL0elMj2TsuJWcDcrOV3I2KDtfydmg7HyDZuvrGv8y\nVgxjzNzc3iFEGa/Z2T19jet0pvseO24lZ4Oy85WcDcrOV3I2KDtfb7Y2TwJt39XzcET8THP7JH7y\nMhDN/dVd909k/kVgSdKEtS3+fwLObm6fDdzSs/9WYCNARDwP2J2ZZT59SlJllr3UExGnAluANcC+\niNgInAtcExG/C/wX8PfN2I8A52XmnRGxMyLuBA4CF40ovyTpCPXz4u5O5t/F0+tlC4w9p+v2poGS\nSZJGwk/uSlJlLH5JqozFL0mVsfglqTIWvyRVxuKXpMpY/JJUGYtfkipj8UtSZSx+SaqMxS9JlbH4\nJakyFr8kVcbil6TKWPySVBmLX5IqY/FLUmUsfkmqjMUvSZVZ9mfuLiQizgde37Xp+Zn5pK79+4Av\ndu0/IzMPtIsoSRqmVsWfmR8EPggQEeuBX+0Z8sPM3DBYNEnSKLQq/h7vAM4dwuNIksZgoOKPiBcA\n92Xm/T27nhgR1wE/B9yUmX85yHEkScMz6Bn/m4BrFth+KfAPwCHgjoi4IzP/ZakHmplZxdTUygHj\njFenMz2SseNWcjYoO1/J2aDsfCVng7LzDZpt0OLfAFzcuzEzP3D4dkTcBjwXWLL45+b2Dhhl/GZn\n9/Q1rtOZ7nvsuJWcDcrOV3I2KDtfydmg7Hy92do8CbQu/og4EXg4Mx/t2R7AO5m/7r8SOB34aNvj\nSJKGa5Az/hOABw7fiYhNwO2Z+aWIuA/4CnAQ2J6ZXxkspiRpWFoXf2buBF7Vdf+yrtt/OGAuSdKI\n+MldSaqMxS9JlbH4JakyFr8kVcbil6TKWPySVBmLX5IqY/FLUmUsfkmqjMUvSZWx+CWpMha/JFXG\n4pekylj8klQZi1+SKmPxS1JlLH5JqozFL0mVsfglqTIWvyRVptUPW4+IDcCNwLeaTXdl5sVd+18K\nvAc4AOzIzHcPmFOSNCStir9xe2ZuXGTf5cArgF3A7RFxU2Z+e4BjSZKGZOiXeiLiZODBzLwvMw8C\nO4Azhn0cSVI7g5zxnxIR24Hjgc2Z+Zlm+2pgtmvcA8Azl3uwmZlVTE2tHCDO+HU60yMZO24lZ4Oy\n85WcDcrOV3I2KDvfoNnaFv/dwGbgBuBk4HMR8azMfHSBsSv6ecC5ub0to0zO7OyevsZ1OtN9jx23\nkrNB2flKzgZl5ys5G5SdrzdbmyeBVsWfmbuA65u790TE/cBJwHeB3cyf9R92UrNNklSAVtf4I+Lc\niLi0ub0aeDrzL+SSmfcCx0XEmoiYAl4N3DqcuJKkQbV9cXc7sD4iPg9sAy4AfiMiXtvsvwD4MPB5\n4PrM/PeBk0qShqLtpZ49wGuW2H8HsK5tKEnS6PjJXUmqjMUvSZWx+CWpMha/JFXG4pekylj8klQZ\ni1+SKmPxS1JlLH5JqozFL0mVsfglqTIWvyRVxuKXpMpY/JJUGYtfkipj8UtSZSx+SaqMxS9JlbH4\nJakyFr8kVabVD1sHiIg/B17YPMZ7M/NjXfvuBe4DDjSbzs3MXe1jSpKGpVXxR8SLgbWZuS4ingp8\nDfhYz7BXZebDgwaUJA1X20s9dwCva27/D3BsRKwcTiRJ0ii1OuPPzAPAj5q75wM7mm3dPhARa4Av\nAG/LzENLPebMzCqmpo6u545OZ3okY8et5GxQdr6Ss0HZ+UrOBmXnGzRb62v8ABFxFvPF//KeXe8A\nbgEeBG4GzgY+utRjzc3tHSTKRMzO7ulrXKcz3ffYcSs5G5Sdr+RsUHa+krNB2fl6s7V5Ehjkxd1X\nAG8HXpmZP+zel5kf6hq3A3guyxS/JGk8Wl3jj4gnA+8DXp2ZD/bui4hPR8Qxzab1wDcHiylJGpa2\nZ/y/BvwscENEHN72WeCuzPx4c5b/5Yj4MfPv+PFsX5IK0fbF3auAq5bY/37g/W1DSZJGx0/uSlJl\nLH5JqozFL0mVsfglqTIWvyRVxuKXpMpY/JJUGYtfkipj8UtSZSx+SaqMxS9JlRno+/hr98bLPjux\nY1+96SUTO7b0eDSpv8+T+LvsGb8kVcbil6TKWPySVBmLX5IqY/FLUmUsfkmqjMUvSZWx+CWpMq0/\nwBURW4HTgEPAJZn51a59LwXeAxwAdmTmuwcNKkkajlZn/BGxHnh2Zq4Dzgcu7xlyOXA2cDrw8og4\nZaCUkqShaXup5wzgZoDM/A4wExHHAUTEycCDmXlfZh4EdjTjJUkFaHupZzWws+v+bLPtoebX2a59\nDwDPXO4BO53pFS2z8IktZ7WdKqDTmZ50hCWVnK/kbFB2vtKyHU09MujaDevF3aVKu3WhS5KGr23x\n72b+zP6wE4HvL7LvpGabJKkAbYv/VmAjQEQ8D9idmXsAMvNe4LiIWBMRU8Crm/GSpAKsOHToUKuJ\nEXEZ8CLgIHAR8IvADzPz4xHxIuDPmqE3ZeZfDCOsJGlwrYtfknR08pO7klQZi1+SKnNU/MzdNl8P\nsdScSWaLiA3AjcC3mmF3ZebFo8jWR74nAn8DPCczn9/PnElmK2ztXgy8l/nf2wTelJkHC1m7x2Rj\n/vW4Utbut5n/xP8B4BvARZl5qJC1e0w2YD2FrF3XmPcC6zJzQ79zuhV/xt/m6yH6mDOxbM322zNz\nQ/PfKP8ALZfvfcDXj3DOxLI1Slm7q4CNmXk6MA28sqC1e0y2ZvvE1y4iVgHnAC9s8v08sK6EtVss\nW7N74mvXNeYU5p/I+57Tq/jip93XQyw6p4Bs47TcOvwR8PEjnDPJbOO0XL5TM/N7ze1Z4Kl9zJlk\ntnFaNF9m7s3MMzJzX1O0TwbuX2pOAdnGqZ912AK8/Qjn/ISjofh7vwLi8NdDLLTvAeCEZeZMOhvA\nKRGxPSK+EBEvG0GufvJx+LMXRzJnwtmgnLV7CCAiTgBezvwTeylrt1A2KGTtmmybgHuAGzLzP/uZ\nM8FsUMjaRcQbgNuBe/uds5Cjofh7tfl6iHF9bUQ/2e4GNgNnAb8FfDAijhl1sJ4Mo57TRj/HKWrt\nIuJpwCeACzPzB/3MGZF+shW1dpl5GXAy85fITu9nzoj0k62ItYuI44HzmD/j72vOYo6GF3fbfD3E\no0vMmWi2zNwFXN9suyci7m/2fXfM+YY5p40jPk5Ja9f8U/pTwNsz89Z+5kwyWylr15TX2sy8IzN/\nHBGfYv41sImv3WLZMvOLFLB2wEuADvB54KeBZzYv6h7x2h0NZ/xtvh5i0TmTzhYR50bEpc2c1cDT\ngV0jyLZkviHPGUu2wtZuC7A1M285gjkTy1bQ2j0BuCYintTc/yXm33lUwtotmK2UtcvMj2bmKZl5\nGvBa4F8z8/eX+X9a0FHxyd1o8fUQvXMy8xslZIuIaeA64CnAMcDmzNyxwEOPI9+NwDOA5zD/NdtX\nZeZ1hazdY7Ixf+li4msHfBqYA77UNfy6zLxq0mu3WDbgwxSwds3v7RuabfuZf8vkBc3bOUv4c/eY\nbMCTKGTtusasAa7pejvnEa3dUVH8kqThORou9UiShsjil6TKWPySVBmLX5IqY/FLUmUsfkmqjMUv\nSZX5PwHkQDycNLUeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f93c3e4c080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "c2UQx2DUOZC_",
        "colab_type": "code",
        "outputId": "05585ce9-df4b-441c-97f2-ecd838bebce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unknown_beta_histogram_cycles = np.isfinite(unknown_beta_histogram_cycles)\n",
        "print(unknown_beta_histogram_cycles)\n",
        "plt.hist(unknown_beta_histogram_cycles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False  True False False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 17.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f93c3e62470>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lj662_E7Qfh0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkImopb4zJiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question 2: Simple Linear Regression with Intercept\n",
        "\n",
        "In this class, you will explore the simple linear regression model (with intercept). That is, we assume that the labels $Y_i$ are independently generated according to \n",
        "$$Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i,$$\n",
        "\n",
        "where the feature $x_i$ is assumed to be fixed and $\\epsilon_i$ is $\\textrm{Normal}(0, \\sigma^2)$. \n",
        "\n",
        "In other words, we assume that the distribution of $Y_i$ is $\\text{Normal}(\\beta_0 + \\beta_1 x_i, \\sigma^2)$, and $Y_1, ..., Y_n$ are independent (but not identically distributed)."
      ]
    },
    {
      "metadata": {
        "id": "yWLbvdqSzJiZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part A. Deriving the MLE from Scratch\n",
        "\n",
        "Use calculus to find $\\hat\\beta_0$, $\\hat\\beta_1$, and $\\hat\\sigma^2$ (the MLEs of $\\beta_0$, $\\beta_1$, and $\\sigma^2$) in terms of $(x_1, Y_1), ..., (x_n, Y_n)$."
      ]
    },
    {
      "metadata": {
        "id": "bt0FXZx-PYeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ L(\\beta_0, \\beta_1, \\sigma^2) = \\prod_{i=1}^{n}\\frac{1}{{ \\sqrt {2\\pi \\sigma^2} }} e^-(yi-(\\beta_0 + \\beta_1x_i))^2 /{2\\sigma ^2 }$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oEot0ntgTPID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ logL(\\beta_0, \\beta_1, \\sigma^2) = \\frac {-n}{2}log2\\pi - \\frac {n}{2}log2\\sigma^2 -  \\frac {1}{2\\sigma^2} \\sum_{i=1} (y_i-(\\beta_0 + \\beta_1x_i))^2$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-kR45FUDXYS2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " $$  \\frac{\\partial logL}{\\partial \\beta_0}= \\frac {1}{\\sigma^2} \\sum_{i=1} (y_i-(\\beta_0 + \\beta_1x_i) $$"
      ]
    },
    {
      "metadata": {
        "id": "qyOGXd42Zu5y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " $$  \\frac{\\partial logL}{\\partial \\beta_1}= \\frac {1}{\\sigma^2} \\sum_{i=1} x_i(y_i- (\\beta_0 + \\beta_1x_i)) $$\n"
      ]
    },
    {
      "metadata": {
        "id": "yJG7tkUYa8Z5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " $$  \\frac{\\partial logL}{\\partial \\sigma^2}= \\frac {1}{2(\\sigma^2)^2} \\sum_{i=1} (y_i- (\\beta_0 + \\beta_1x_i))^2 - \\frac{n}{2\\sigma^2} $$\n"
      ]
    },
    {
      "metadata": {
        "id": "3SuXgfu8yzH5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ \\beta0 = \\frac{\\sum_{i=1}y_{i} - \\beta1\\sum_{i=1}x_{i}}{n} = \\bar{y} - \\beta1\\bar{x}  $$ "
      ]
    },
    {
      "metadata": {
        "id": "iasNwkrO0KOH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ \\sum_{i = 1}x_{i}y_{i} - \\beta0\\sum_{i = 1}x_{i} - \\sum_{i=1} \\beta1xi^2 = 0 $$"
      ]
    },
    {
      "metadata": {
        "id": "s-S_6kSf200i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ \\sum_{i = 1}x_{i}y_{i} - (\\bar{y} - \\bar{\\beta1}\\bar{x})\\sum_{i = 1}x_{i} - \\sum_{i=1} \\beta1xi^2 = 0 $$"
      ]
    },
    {
      "metadata": {
        "id": "KI474QwIzJid",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part B. Deriving the MLE from the Multiple Regression Formula\n",
        "\n",
        "In class, we showed that for multiple linear regression, the _vector_ $\\hat\\beta$ of estimated coefficients is given by the formula\n",
        "$$\\hat\\beta = (X^T X)^{-1} X^T {\\bf y},$$\n",
        "where $X$ is an $n \\times d$ matrix of features and ${\\bf y}$ is a length-$n$ vector of labels.\n",
        "\n",
        "By constructing a suitable matrix $X$ for simple linear regression, re-derive the simple linear regression estimates $\\hat\\beta_0$ and $\\hat\\beta_1$ using the multiple regression formula above."
      ]
    },
    {
      "metadata": {
        "id": "hnu2GLxBh2rT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i$$ $\n",
        "where $ i = 1,..., n$$\n",
        "\n",
        "$$Y_1 = \\beta_0 + \\beta_1X_1 + \\epsilon_1 $$\n",
        "$$Y_2 = \\beta_0 + \\beta_1X_2 + \\epsilon_2 $$\n",
        "...\n",
        "$$Y_n = \\beta_0 + \\beta_1X_n + \\epsilon_n $$\n",
        "\n",
        "Y is a n by 1 matrix. X is a n by 2 matrix with the first column being all ones. B is a 2 by 1 matrix. E is a n by 1 matrix. \n",
        "\n",
        "\n",
        "$$ \\begin{bmatrix}\n",
        "    Y_{1}       \\\\\n",
        "    Y_{2}       \\\\\n",
        "    ... \\\\\n",
        "    Y_{n}       \n",
        "\\end{bmatrix}\n",
        "= Y (n x 1 matrix)$$\n",
        "\n",
        "\n",
        "$$ \\begin{bmatrix}\n",
        "    1 & X_{1}       \\\\\n",
        "    1 & X_{2}       \\\\\n",
        "    ... \\\\\n",
        "    1 & X_{n}       \n",
        "\\end{bmatrix}\n",
        "= X (n x 2 matrix)$$\n",
        "\n",
        "\n",
        "$$ \\begin{bmatrix}\n",
        "    \\beta_{0}       \\\\\n",
        "    \\beta_{1}       \n",
        "\\end{bmatrix}\n",
        "= \\beta (2 x 1 matrix)$$\n",
        "\n",
        "$$ \\begin{bmatrix}\n",
        "    \\epsilon_{1}       \\\\\n",
        "    \\epsilon_{2}       \\\\\n",
        "    ... \\\\\n",
        "    \\epsilon_{n}       \n",
        "\\end{bmatrix}\n",
        "= \\epsilon (n x 1 matrix)$$\n",
        "\n",
        "\n",
        "The simple linear regression formula can be expressed as below in matrix form:\n",
        "$$ Y = X\\beta + \\epsilon$$\n",
        "\n",
        "Both beta values can be found using this formula:\n",
        "\n",
        "$$ \\frac{1}{\\sigma^2}\\sum_{i=1}^n (y_i - x_i^T \\beta)x_{ij} = 0$$\n",
        "$$ \\frac{1}{\\sigma^2}\\sum_{i=1}^n (y_i - x_i^T \\beta)1 = 0$$\n",
        "$$ X^T(Y - X\\beta) = 0$$\n",
        "$$ X^T - X^TX\\beta = 0$$\n",
        "$$ X^T - X\\beta = X^TY$$\n",
        "$$\\beta = (X^TX)^-1 (X^TY)$$\n"
      ]
    },
    {
      "metadata": {
        "id": "tVqpjqw6zJih",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Submission Instructions\n",
        "\n",
        "Once you are finished with this assignment, please export this notebook to PDF. You can do this by going to `File > Export Notebook As > PDF`. If this does not work, try exporting to HTML and then printing the resulting webpage to PDF. Print out the PDF and submit a paper copy of this assignment."
      ]
    }
  ]
}